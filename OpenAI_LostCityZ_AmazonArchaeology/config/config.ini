[DEFAULT]
# Define your Copernicus Open Access Hub (SciHub) or PEPS credentials
# PEPS (https://peps.cnes.fr) is often more reliable for consistent access.
# Register at https://peps.cnes.fr/register if you don't have an account.
# IMPORTANT: Replace with your actual credentials before running.
api_user = YOUR_USERNAME_HERE 
api_password = YOUR_PASSWORD_HERE
# API URL for PEPS Sentinel-2 products
api_url = https://peps.cnes.fr/resto/api/collections/S2ST 

# Define your Area of Interest (AOI)
# Option 1: Bounding Box (lon_min, lat_min, lon_max, lat_max) in WGS84 (EPSG:4326)
# Example: A small area near Manaus, Brazil (approx. 55x55km)
# This is a small AOI suitable for initial testing.
aoi_bbox = -60.0, -3.0, -59.5, -2.5

# Option 2: Path to a GeoJSON file defining the AOI (more precise for complex shapes)
# If aoi_geojson_path is provided and valid, it will override aoi_bbox.
# aoi_geojson_path = path/to/your/aoi.geojson
aoi_geojson_path = 

# Data Acquisition Parameters
# Dates in YYYYMMDD format
start_date = 20230701 
end_date = 20230731
# Maximum cloud cover percentage allowed for a Sentinel-2 tile
cloud_cover_percentage = 10 

# Output Directories
# These paths are relative to the location of the main script that loads them.
# For satellite pipeline scripts in scripts/satellite_pipeline/, ../../data means root/data
# For lidar pipeline scripts in scripts/lidar_pipeline/, ../../data also means root/data
# Ensure these base directories (data, logs) exist at the project root.
# The specific subdirectories (sentinel2, lidar) will be created by the scripts if they don't exist.

# Common log directory
log_dir = ../../logs # Relative to script location, so goes to project_root/logs
# Specific log file name can be set per pipeline, or use a shared one.
satellite_log_file_name = satellite_pipeline.log 
lidar_log_file_name = lidar_pipeline.log
text_pipeline_log_file_name = text_pipeline.log


# Base data directories (relative to script location)
base_raw_data_dir = ../../data
base_processed_data_dir = ../../data

# Sentinel-2 specific paths (appended to base dirs)
s2_raw_suffix = sentinel2/raw
s2_processed_suffix = sentinel2/processed

# Product Type for Sentinel-2
# S2MSI2A = Level-2A (Surface Reflectance, atmospherically corrected) - PREFERRED
# S2MSI1C = Level-1C (Top of Atmosphere) - Requires atmospheric correction using Sen2Cor
product_type = S2MSI2A

[SEN2COR]
# Optional: Path to Sen2Cor L2A_Process script (executable: L2A_Process.bat on Windows, L2A_Process.sh on Linux/macOS)
sen2cor_path = 
# sen2cor_threads = 0 

[PREPROCESSING]
# Target resolution for processed Sentinel-2 imagery in meters. 
target_resolution = 10
# Select bands to include in the processed Sentinel-2 output. Comma-separated list.
output_bands = B02,B03,B04,B08
# Cloud masking method for Sentinel-2
cloud_mask_method = scl
# SCL classes to mask for Sentinel-2
scl_mask_classes = 3,8,9,10,11


[LIDAR]
# List of direct download URLs for LiDAR files (LAZ or LAS)
lidar_data_urls = 
    # https://SOME_VALID_HOST/path/to/your/lidar_data_1.laz

# LiDAR specific paths (appended to base_raw_data_dir and base_processed_data_dir from DEFAULT)
lidar_raw_suffix = lidar/raw
lidar_processed_suffix = lidar/processed 

# DTM Generation Parameters
dtm_resolution = 1.0 
dtm_interpolation_method = mean 

# CRS Management for LiDAR
# ** Users MUST change this to a CRS suitable for their AOI **
target_projected_crs = EPSG:31980 

# PDAL Pipeline for Ground Classification (SMRF example)
ground_classification_pipeline_json = """
{
    "pipeline": [
        {
            "type": "readers.las",
            "filename": "INPUT_FILE_PLACEHOLDER"
        },
        {
            "type": "filters.reprojection",
            "out_srs": "TARGET_PROJECTED_CRS_PLACEHOLDER"
        },
        {
            "type": "filters.smrf",
            "scalar": 1.2,
            "slope": 0.15,
            "threshold": 0.45,
            "window": 18.0,
            "ignore": "Classification[7:7]"
        },
        {
            "type": "filters.range",
            "limits": "Classification[2:2]"
        },
        {
            "type": "writers.las",
            "filename": "OUTPUT_GROUND_FILE_PLACEHOLDER",
            "forward": ["header","vlr"],
            "a_srs": "TARGET_PROJECTED_CRS_PLACEHOLDER"
        }
    ]
}
"""

# PDAL Pipeline for DTM Generation
dtm_generation_pipeline_json = """
{
    "pipeline": [
        {
            "type": "readers.las",
            "filename": "INPUT_GROUND_POINTS_PLACEHOLDER"
        },
        {
            "type": "writers.gdal",
            "filename": "OUTPUT_DTM_FILE_PLACEHOLDER",
            "gdaldriver": "GTiff",
            "output_type": "DTM_INTERPOLATION_METHOD_PLACEHOLDER",
            "resolution": "DTM_RESOLUTION_PLACEHOLDER",
            "a_srs": "TARGET_PROJECTED_CRS_PLACEHOLDER",
            "override_srs": "TARGET_PROJECTED_CRS_PLACEHOLDER" 
        }
    ]
}
"""

# Hillshade Parameters (used by GDAL, via Rasterio)
hillshade_azimuth = 315
hillshade_altitude = 45
hillshade_z_factor = 1 
multi_directional_hillshade = true 

[TextualData]
# List of URLs to fetch. Specify type if known, otherwise script will try to infer.
# Format: URL | TYPE (Optional: TXT, HTML, PDF, PDF_OCR) | Custom_Output_Filename (Optional, without extension)
text_data_sources =
    https://www.gutenberg.org/files/1342/1342-0.txt | TXT | pride_and_prejudice_gutenberg
    # https://example-news-site.com/article-on-amazon | HTML | example_amazon_article
    # https://arxiv.org/pdf/2301.00001.pdf | PDF | arxiv_paper_2301_00001
    # https://example.com/scanned_document.pdf | PDF_OCR | my_scanned_document

# Output Suffixes (appended to base_raw_data_dir and base_processed_data_dir from DEFAULT)
text_raw_suffix = textual/raw
text_processed_suffix = textual/processed
ocr_intermediate_suffix = textual/ocr_intermediate # For storing per-page images or hOCR from Tesseract

# Preprocessing Settings
force_reprocess_raw = false 
force_reprocess_processed = false 

clean_text_to_lowercase = true
# Custom characters/patterns to remove (JSON list of regex patterns). Applied after basic cleaning.
# Example: ["\\b[A-Z]\\.\\s?", "[\\\"\\']"] 
custom_remove_patterns_json = [] 

# Specific languages for Tesseract OCR, comma-separated (e.g., eng, por, spa)
# Only used if PDF_OCR type is specified or OCR is attempted on image-based PDFs.
ocr_languages = eng+por+spa

# Tesseract OCR Path (if not in system PATH or to specify a version)
# Example Windows: C:/Program Files/Tesseract-OCR/tesseract.exe
# Example Linux: /usr/bin/tesseract
tesseract_cmd_path = 

# PDF Processing Settings
# "native" - uses pdfminer.six text extraction.
# "ocr_only" - forces OCR for all pages of PDF (useful for scanned docs mistakenly not marked PDF_OCR).
# "hybrid" - (Future idea) try native, if very little text extracted, then OCR. Not implemented.
pdf_extraction_method = native
# DPI for rendering PDF pages to images for OCR. Higher DPI can improve OCR but is slower.
pdf_ocr_dpi = 300
