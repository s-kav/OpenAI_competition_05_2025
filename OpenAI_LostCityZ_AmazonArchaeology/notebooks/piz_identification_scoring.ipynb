{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Interest Zone (PIZ) Identification and Scoring\n",
    "\n",
    "This notebook implements an initial system for identifying and scoring Potential Interest Zones (PIZs) based on the `SITE_PREDICTION_VERIFICATION_STRATEGY.md` and simulated outputs from the Phase 3 EDA notebooks.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Load (placeholder/simulated) EDA outputs for LiDAR, Satellite, and Textual data.\n",
    "2. Define initial PIZs based on spatial proximity/overlap of anomalies from different sources.\n",
    "3. Implement a heuristic scoring system to rank PIZs.\n",
    "4. Demonstrate conceptual OpenAI prompt formulation for plausibility assessment of top PIZs.\n",
    "5. Visualize PIZs on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon, box\n",
    "from shapely.ops import unary_union\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json # For OpenAI prompt structuring\n",
    "\n",
    "# Helper for pretty printing JSON\n",
    "def print_json(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"../scripts/satellite_pipeline/config.ini\" # Adjust if your config is elsewhere\n",
    "SCRIPT_DIR = Path(\".\").resolve().parent # Assuming notebook is in 'notebooks' dir, so parent is project root\n",
    "EDA_OUTPUT_DIR_PIZ = SCRIPT_DIR / \"eda_outputs\" / \"piz\"\n",
    "EDA_OUTPUT_DIR_PIZ.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_config(config_path):\n",
    "    config = configparser.ConfigParser(interpolation=None, allow_no_value=True)\n",
    "    if not Path(config_path).exists():\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "    config.read(config_path)\n",
    "    return config\n",
    "\n",
    "config = load_config(CONFIG_FILE_PATH)\n",
    "\n",
    "# Get AOI (used for context and potential gridding)\n",
    "aoi_bbox_str = config['DEFAULT'].get('aoi_bbox')\n",
    "aoi_geojson_path_str = config['DEFAULT'].get('aoi_geojson_path')\n",
    "aoi_boundary_gdf = None # This will be a GeoDataFrame representing the AOI\n",
    "TARGET_PROJECTED_CRS = config['LIDAR'].get('target_projected_crs', 'EPSG:32620') # Default to a UTM zone if not set\n",
    "\n",
    "if aoi_geojson_path_str:\n",
    "    # Construct path relative to project root, assuming config paths are relative to `scripts/satellite_pipeline`\n",
    "    # Config path: scripts/satellite_pipeline/config.ini -> ../../ -> project root\n",
    "    # Notebook path: notebooks/piz_identification_scoring.ipynb -> ../ -> project root\n",
    "    # So, if aoi_geojson_path is like 'path/to/aoi.geojson' it means 'project_root/path/to/aoi.geojson'\n",
    "    # This logic needs to be robust based on where the config file expects paths to be relative to.\n",
    "    # For simplicity, assume aoi_geojson_path is relative to project root if not absolute.\n",
    "    potential_aoi_path = Path(aoi_geojson_path_str)\n",
    "    if not potential_aoi_path.is_absolute():\n",
    "        potential_aoi_path = SCRIPT_DIR / potential_aoi_path\n",
    "    \n",
    "    if potential_aoi_path.exists():\n",
    "        aoi_boundary_gdf = geopandas.read_file(potential_aoi_path)\n",
    "        print(f\"Loaded AOI from GeoJSON: {potential_aoi_path}\")\n",
    "    else:\n",
    "        print(f\"AOI GeoJSON path in config not found: {potential_aoi_path}\")\n",
    "\n",
    "if aoi_boundary_gdf is None and aoi_bbox_str: # Fallback to BBOX if GeoJSON not loaded\n",
    "    coords = [float(c.strip()) for c in aoi_bbox_str.split(',')]\n",
    "    minx, miny, maxx, maxy = coords\n",
    "    aoi_boundary_gdf = geopandas.GeoDataFrame([{'geometry': box(minx, miny, maxx, maxy)}], crs=\"EPSG:4326\")\n",
    "    print(f\"Using AOI from BBOX (EPSG:4326): {coords}\")\n",
    "elif aoi_boundary_gdf is None:\n",
    "    print(\"CRITICAL: No AOI geometry defined in config. Using a placeholder AOI.\")\n",
    "    # Placeholder AOI (e.g., a 10km x 10km square in a projected CRS for simplicity if no config AOI)\n",
    "    # This is just for the notebook to run; real analysis needs a proper AOI.\n",
    "    aoi_boundary_gdf = geopandas.GeoDataFrame([{'geometry': box(0, 0, 10000, 10000)}], crs=TARGET_PROJECTED_CRS)\n",
    "\n",
    "# Ensure AOI is in the target projected CRS for spatial operations\n",
    "if aoi_boundary_gdf.crs.to_string().lower() != TARGET_PROJECTED_CRS.lower():\n",
    "    print(f\"Reprojecting AOI from {aoi_boundary_gdf.crs} to {TARGET_PROJECTED_CRS}\")\n",
    "    aoi_boundary_gdf = aoi_boundary_gdf.to_crs(TARGET_PROJECTED_CRS)\n",
    "\n",
    "print(f\"AOI CRS: {aoi_boundary_gdf.crs}\")\n",
    "aoi_total_bounds = aoi_boundary_gdf.total_bounds # (minx, miny, maxx, maxy)\n",
    "print(f\"AOI total bounds (in {aoi_boundary_gdf.crs}): {aoi_total_bounds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load (Placeholder) EDA Outputs\n",
    "\n",
    "In a real workflow, these would be outputs from the Phase 3 EDA notebooks (`lidar_eda.ipynb`, `satellite_eda.ipynb`, `textual_eda_openai.ipynb`). For this implementation, we'll use manually curated placeholder data. Each anomaly will be represented as a point or polygon with some basic attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder EDA Outputs - Assume these are GeoDataFrames in the TARGET_PROJECTED_CRS\n",
    "\n",
    "# LiDAR Anomalies (e.g., mounds, linear features)\n",
    "# Attributes: 'lidar_clarity' (1-5), 'feature_type' (e.g., 'mound', 'linear_depression')\n",
    "lidar_anomalies_data = {\n",
    "    'geometry': [\n",
    "        Point(aoi_total_bounds[0] + 1000, aoi_total_bounds[1] + 1000), # Anomaly 1\n",
    "        box(aoi_total_bounds[0] + 2000, aoi_total_bounds[1] + 2000, \n",
    "            aoi_total_bounds[0] + 2100, aoi_total_bounds[1] + 2300)  # Anomaly 2 (linear/rectangular)\n",
    "    ],\n",
    "    'lidar_clarity': [4, 5], # Score 1-5\n",
    "    'lidar_feature_type': ['point_mound', 'linear_earthwork']\n",
    "}\n",
    "lidar_anomalies_gdf = geopandas.GeoDataFrame(lidar_anomalies_data, crs=TARGET_PROJECTED_CRS)\n",
    "print(f\"Loaded {len(lidar_anomalies_gdf)} LiDAR anomalies.\")\n",
    "\n",
    "# Satellite Anomalies (e.g., unusual NDVI, geometric vegetation pattern)\n",
    "# Attributes: 'satellite_significance' (1-5), 'anomaly_type' (e.g., 'ndvi_low', 'veg_pattern_geometric')\n",
    "satellite_anomalies_data = {\n",
    "    'geometry': [\n",
    "        Point(aoi_total_bounds[0] + 1050, aoi_total_bounds[1] + 1050), # Near LiDAR Anomaly 1\n",
    "        Point(aoi_total_bounds[0] + 3000, aoi_total_bounds[1] + 3000)  # Standalone satellite anomaly\n",
    "    ],\n",
    "    'satellite_significance': [3, 4],\n",
    "    'satellite_anomaly_type': ['ndvi_low_circular', 'veg_pattern_geometric']\n",
    "}\n",
    "satellite_anomalies_gdf = geopandas.GeoDataFrame(satellite_anomalies_data, crs=TARGET_PROJECTED_CRS)\n",
    "print(f\"Loaded {len(satellite_anomalies_gdf)} Satellite anomalies.\")\n",
    "\n",
    "# Textual Mentions (Geocoded points of interest from text)\n",
    "# Attributes: 'textual_reliability' (1-5), 'mention_type' (e.g., 'settlement_described', 'resource_area')\n",
    "textual_mentions_data = {\n",
    "    'geometry': [\n",
    "        Point(aoi_total_bounds[0] + 950, aoi_total_bounds[1] + 950),   # Near LiDAR Anomaly 1 & Sat Anomaly 1\n",
    "        Point(aoi_total_bounds[0] + 4000, aoi_total_bounds[1] + 4000)  # Standalone textual mention\n",
    "    ],\n",
    "    'textual_reliability': [4, 2],\n",
    "    'textual_mention_type': ['settlement_possible_ruins', 'general_region_activity_X']\n",
    "}\n",
    "textual_mentions_gdf = geopandas.GeoDataFrame(textual_mentions_data, crs=TARGET_PROJECTED_CRS)\n",
    "print(f\"Loaded {len(textual_mentions_gdf)} Textual mentions.\")\n",
    "\n",
    "# --- (Optional) Load other relevant features like water sources ---\n",
    "# Example: rivers_gdf = geopandas.read_file(\"path/to/rivers.shp\").to_crs(TARGET_PROJECTED_CRS)\n",
    "# For now, we'll simulate this if needed in scoring.\n",
    "water_sources_data = {\n",
    "    'geometry': [Point(aoi_total_bounds[0] + 1500, aoi_total_bounds[1] + 1500)],\n",
    "    'water_type': ['river_segment']\n",
    "}\n",
    "water_sources_gdf = geopandas.GeoDataFrame(water_sources_data, crs=TARGET_PROJECTED_CRS)\n",
    "print(f\"Loaded {len(water_sources_gdf)} water sources (placeholder).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Potential Interest Zones (PIZs)\n",
    "\n",
    "We'll use a simple approach: create buffers around each anomaly and then find areas where these buffers overlap (intersections). An alternative is gridding the AOI, which is also discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. PIZ Definition by Proximity/Overlap of Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_DISTANCE_METERS = 200 # Define a buffer distance (e.g., 200 meters)\n",
    "\n",
    "# Create buffers\n",
    "lidar_buffers = lidar_anomalies_gdf.copy()\n",
    "lidar_buffers['geometry'] = lidar_anomalies_gdf.geometry.buffer(BUFFER_DISTANCE_METERS)\n",
    "lidar_buffers['source'] = 'lidar'\n",
    "\n",
    "satellite_buffers = satellite_anomalies_gdf.copy()\n",
    "satellite_buffers['geometry'] = satellite_anomalies_gdf.geometry.buffer(BUFFER_DISTANCE_METERS)\n",
    "satellite_buffers['source'] = 'satellite'\n",
    "\n",
    "textual_buffers = textual_mentions_gdf.copy()\n",
    "textual_buffers['geometry'] = textual_mentions_gdf.geometry.buffer(BUFFER_DISTANCE_METERS * 1.5) # Larger buffer for less precise textual data\n",
    "textual_buffers['source'] = 'textual'\n",
    "\n",
    "# Combine all buffered anomalies into one GeoDataFrame\n",
    "all_buffers = pd.concat([lidar_buffers, satellite_buffers, textual_buffers], ignore_index=True)\n",
    "\n",
    "# --- Create PIZs by finding intersections of buffers from DIFFERENT sources ---\n",
    "# This is a simplified approach. A more robust way would be to iterate and intersect pairs, \n",
    "# or use spatial clustering on original points, then evaluate sources within clusters.\n",
    "# For now, let's find areas covered by at least two different types of buffers by dissolving overlapping buffers.\n",
    "\n",
    "# Dissolve all overlapping buffers to get initial candidate zones\n",
    "dissolved_zones = all_buffers.dissolve(by=None) # 'by=None' dissolves all into one if they overlap\n",
    "dissolved_zones['piz_id'] = range(len(dissolved_zones))\n",
    "\n",
    "piz_gdf = geopandas.GeoDataFrame(columns=['piz_id', 'geometry', 'contributing_sources', 'lidar_features', 'satellite_features', 'textual_features'], crs=TARGET_PROJECTED_CRS)\n",
    "\n",
    "temp_piz_list = []\n",
    "\n",
    "for idx, dissolved_zone in dissolved_zones.iterrows():\n",
    "    intersecting_original_anomalies = []\n",
    "    sources_in_zone = set()\n",
    "    \n",
    "    # Check original anomalies (not buffers) within this dissolved zone\n",
    "    # LiDAR\n",
    "    lidar_intersect = lidar_anomalies_gdf[lidar_anomalies_gdf.geometry.intersects(dissolved_zone.geometry)]\n",
    "    if not lidar_intersect.empty:\n",
    "        sources_in_zone.add('lidar')\n",
    "        intersecting_original_anomalies.extend(lidar_intersect.apply(lambda row: f\"L: {row.lidar_feature_type} (Clarity: {row.lidar_clarity})\", axis=1).tolist())\n",
    "        \n",
    "    # Satellite\n",
    "    satellite_intersect = satellite_anomalies_gdf[satellite_anomalies_gdf.geometry.intersects(dissolved_zone.geometry)]\n",
    "    if not satellite_intersect.empty:\n",
    "        sources_in_zone.add('satellite')\n",
    "        intersecting_original_anomalies.extend(satellite_intersect.apply(lambda row: f\"S: {row.satellite_anomaly_type} (Sig: {row.satellite_significance})\", axis=1).tolist())\n",
    "\n",
    "    # Textual\n",
    "    textual_intersect = textual_mentions_gdf[textual_mentions_gdf.geometry.intersects(dissolved_zone.geometry)]\n",
    "    if not textual_intersect.empty:\n",
    "        sources_in_zone.add('textual')\n",
    "        intersecting_original_anomalies.extend(textual_intersect.apply(lambda row: f\"T: {row.textual_mention_type} (Rel: {row.textual_reliability})\", axis=1).tolist())\n",
    "\n",
    "    # Only consider zones with evidence from at least two sources, or very strong single source (for this demo, use 2)\n",
    "    if len(sources_in_zone) >= 1: # For demo, let's use 1 to see all zones, scoring will differentiate\n",
    "        temp_piz_list.append({\n",
    "            'piz_id': dissolved_zone.piz_id,\n",
    "            'geometry': dissolved_zone.geometry,\n",
    "            'num_sources': len(sources_in_zone),\n",
    "            'contributing_sources': \", \".join(sorted(list(sources_in_zone))),\n",
    "            'lidar_features': [f['lidar_feature_type'] for i,f in lidar_intersect.iterrows()] if not lidar_intersect.empty else [],\n",
    "            'lidar_clarity_max': lidar_intersect['lidar_clarity'].max() if not lidar_intersect.empty else 0,\n",
    "            'satellite_features': [f['satellite_anomaly_type'] for i,f in satellite_intersect.iterrows()] if not satellite_intersect.empty else [],\n",
    "            'satellite_significance_max': satellite_intersect['satellite_significance'].max() if not satellite_intersect.empty else 0,\n",
    "            'textual_features': [f['textual_mention_type'] for i,f in textual_intersect.iterrows()] if not textual_intersect.empty else [],\n",
    "            'textual_reliability_max': textual_intersect['textual_reliability'].max() if not textual_intersect.empty else 0,\n",
    "            'all_intersecting_features_desc': \"; \".join(intersecting_original_anomalies)\n",
    "        })\n",
    "\n",
    "piz_gdf = geopandas.GeoDataFrame(temp_piz_list, crs=TARGET_PROJECTED_CRS)\n",
    "piz_gdf = piz_gdf[piz_gdf.num_sources >=1] # Filter for PIZs with at least 1 source for this demo\n",
    "piz_gdf['piz_id'] = range(len(piz_gdf)) # Re-ID after filtering\n",
    "\n",
    "print(f\"Identified {len(piz_gdf)} initial PIZs with >=1 source types.\")\n",
    "if not piz_gdf.empty:\n",
    "    display(piz_gdf[['piz_id', 'num_sources', 'contributing_sources', 'all_intersecting_features_desc']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. PIZ Definition by Gridding (Alternative/Conceptual)\n",
    "\n",
    "1.  Create a grid over the AOI (e.g., 100m x 100m cells).\n",
    "2.  For each cell, count LiDAR anomalies, satellite anomalies, and textual mentions falling within it.\n",
    "3.  Cells with high counts or a mix of anomaly types become PIZs.\n",
    "\n",
    "```python\n",
    "# # Conceptual Gridding Example (not fully implemented for brevity)\n",
    "# GRID_CELL_SIZE = 100 # meters\n",
    "# minx, miny, maxx, maxy = aoi_total_bounds\n",
    "# grid_cells = []\n",
    "# for x in np.arange(minx, maxx, GRID_CELL_SIZE):\n",
    "#     for y in np.arange(miny, maxy, GRID_CELL_SIZE):\n",
    "#         cell = box(x, y, x + GRID_CELL_SIZE, y + GRID_CELL_SIZE)\n",
    "#         grid_cells.append({'geometry': cell})\n",
    "# grid_gdf = geopandas.GeoDataFrame(grid_cells, crs=TARGET_PROJECTED_CRS)\n",
    "# grid_gdf['cell_id'] = range(len(grid_gdf))\n",
    "# \n",
    "# # Perform spatial joins to count anomalies per cell\n",
    "# # lidar_in_grid = geopandas.sjoin(grid_gdf, lidar_anomalies_gdf, how='left', op='intersects')\n",
    "# # ... and so on for other sources ...\n",
    "# # Then group by cell_id and count/score.\n",
    "```\n",
    "The buffer/overlap method is generally more direct for feature-driven PIZ creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement Heuristic Scoring System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for scoring factors (can be tuned)\n",
    "weights = {\n",
    "    'num_sources': 3.0,        # e.g., 1 source=1, 2 sources=2, 3 sources=3\n",
    "    'lidar_clarity': 2.0,      # Max score from LiDAR anomalies in PIZ (1-5 scale)\n",
    "    'satellite_significance': 2.0, # Max score from Satellite anomalies (1-5 scale)\n",
    "    'textual_reliability': 1.5, # Max score from Textual mentions (1-5 scale)\n",
    "    'proximity_to_water': 0.5, # Bonus if PIZ is near water (binary 0 or 1, or scaled by distance)\n",
    "    'uniqueness_factor': 1.0 # Placeholder for future feature, e.g. how rare the pattern is\n",
    "}\n",
    "\n",
    "def calculate_piz_score(row):\n",
    "    score = 0\n",
    "    \n",
    "    # Score from number of unique sources\n",
    "    score += row['num_sources'] * weights['num_sources']\n",
    "    \n",
    "    # Score from LiDAR (using max clarity of features within PIZ)\n",
    "    if 'lidar' in row['contributing_sources']:\n",
    "        score += row['lidar_clarity_max'] * weights['lidar_clarity']\n",
    "        \n",
    "    # Score from Satellite (using max significance)\n",
    "    if 'satellite' in row['contributing_sources']:\n",
    "        score += row['satellite_significance_max'] * weights['satellite_significance']\n",
    "        \n",
    "    # Score from Textual (using max reliability)\n",
    "    if 'textual' in row['contributing_sources']:\n",
    "        score += row['textual_reliability_max'] * weights['textual_reliability']\n",
    "        \n",
    "    # (Optional) Proximity to water (example)\n",
    "    # This requires water_sources_gdf to be defined and populated\n",
    "    if not water_sources_gdf.empty:\n",
    "        # Check if the PIZ (its geometry: row.geometry) intersects with any buffered water source\n",
    "        # A more sophisticated approach would be distance-based scaling.\n",
    "        WATER_BUFFER_METERS = 100 # Considered 'near water' if within this distance\n",
    "        if any(row.geometry.intersects(water_buffer) for water_buffer in water_sources_gdf.geometry.buffer(WATER_BUFFER_METERS)):\n",
    "            score += 1.0 * weights['proximity_to_water'] # Binary bonus\n",
    "            \n",
    "    # Add uniqueness factor (placeholder)\n",
    "    # score += (row.get('uniqueness_score', 0) * weights['uniqueness_factor'])\n",
    "            \n",
    "    return score\n",
    "\n",
    "if not piz_gdf.empty:\n",
    "    piz_gdf['score'] = piz_gdf.apply(calculate_piz_score, axis=1)\n",
    "    piz_gdf_sorted = piz_gdf.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    print(\"\\n--- Top Scored PIZs ---\")\n",
    "    display(piz_gdf_sorted[['piz_id', 'score', 'num_sources', 'contributing_sources', 'all_intersecting_features_desc']].head())\n",
    "else:\n",
    "    print(\"No PIZs identified to score.\")\n",
    "    piz_gdf_sorted = piz_gdf # Keep it as an empty GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. OpenAI for Plausibility Assessment (Conceptual Integration)\n",
    "\n",
    "For the top-scoring PIZs, we can formulate a prompt to send to an OpenAI model to get a qualitative assessment of archaeological plausibility, as outlined in `SITE_PREDICTION_VERIFICATION_STRATEGY.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulate_openai_plausibility_prompt(piz_row):\n",
    "    evidence_summary = []\n",
    "    if 'lidar' in piz_row['contributing_sources']:\n",
    "        evidence_summary.append(f\"- LiDAR evidence: Max clarity score {piz_row['lidar_clarity_max']}. Features include: {', '.join(piz_row['lidar_features'])}.\")\n",
    "    if 'satellite' in piz_row['contributing_sources']:\n",
    "        evidence_summary.append(f\"- Satellite imagery evidence: Max significance score {piz_row['satellite_significance_max']}. Features include: {', '.join(piz_row['satellite_features'])}.\")\n",
    "    if 'textual' in piz_row['contributing_sources']:\n",
    "        evidence_summary.append(f\"- Textual evidence: Max reliability score {piz_row['textual_reliability_max']}. Mentions include: {', '.join(piz_row['textual_features'])}.\")\n",
    "    \n",
    "    # Get centroid for representative coordinates (in original projected CRS for now)\n",
    "    # For actual reporting, might want to convert to WGS84 (Lat/Lon)\n",
    "    centroid = piz_row.geometry.centroid\n",
    "    coords_str = f\"{centroid.x:.2f}, {centroid.y:.2f} (CRS: {piz_gdf.crs.to_string()})\"\n",
    "\n",
    "    prompt = f\"\"\"Assess the archaeological plausibility of the following Potential Interest Zone (PIZ):\n",
    "\n",
    "PIZ ID: {piz_row['piz_id']}\n",
    "Approximate Coordinates: {coords_str}\n",
    "Total Score (heuristic): {piz_row['score']:.2f}\n",
    "Number of contributing data source types: {piz_row['num_sources']}\n",
    "\n",
    "Summary of Evidence:\n",
    "\"\"\"\n",
    "    prompt += \"\\n\".join(evidence_summary)\n",
    "    prompt += \"\"\"\n",
    "\n",
    "Based on this combined evidence:\n",
    "1. What type of archaeological site or features might this represent in an Amazonian context?\n",
    "2. What are common characteristics of such sites in the Amazon?\n",
    "3. Are there any alternative (non-archaeological) explanations for these combined features?\n",
    "4. What specific aspects of the evidence make this PIZ more or less plausible?\n",
    "5. What further investigation steps (using available data types or suggesting new ones) would you recommend to clarify the nature of this PIZ?\n",
    "\n",
    "Provide a concise assessment.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "if not piz_gdf_sorted.empty:\n",
    "    print(\"\\n--- Example OpenAI Plausibility Prompts for Top PIZs ---\")\n",
    "    for i, (idx, row) in enumerate(piz_gdf_sorted.head(2).iterrows()): # Show for top 2\n",
    "        print(f\"\\n--- Prompt for PIZ ID: {row['piz_id']} ---\")\n",
    "        example_prompt = formulate_openai_plausibility_prompt(row)\n",
    "        print(example_prompt)\n",
    "        # In a real scenario, this prompt would be sent to an OpenAI model:\n",
    "        # client = OpenAI() # Assuming client is initialized\n",
    "        # response = client.chat.completions.create(\n",
    "        #     model=\"gpt-4-turbo-preview\", # Or other suitable model\n",
    "        #     messages=[\n",
    "        #         {\"role\": \"system\", \"content\": \"You are an AI assistant with expertise in Amazonian archaeology and multi-source data interpretation.\"},\n",
    "        #         {\"role\": \"user\", \"content\": example_prompt}\n",
    "        #     ]\n",
    "        # )\n",
    "        # plausibility_assessment = response.choices[0].message.content\n",
    "        # print(f\"\\nOpenAI Plausibility Assessment for PIZ {row['piz_id']}:\\n{plausibility_assessment}\")\n",
    "else:\n",
    "    print(\"No PIZs available to generate OpenAI prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of PIZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not piz_gdf_sorted.empty:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "    \n",
    "    # Plot AOI boundary\n",
    "    aoi_boundary_gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=2, label='AOI Boundary', zorder=1)\n",
    "    \n",
    "    # Plot original anomalies for context (optional, can make plot busy)\n",
    "    lidar_anomalies_gdf.plot(ax=ax, marker='o', color='blue', markersize=50, label='LiDAR Anomalies', alpha=0.7, zorder=2)\n",
    "    satellite_anomalies_gdf.plot(ax=ax, marker='^', color='green', markersize=50, label='Satellite Anomalies', alpha=0.7, zorder=2)\n",
    "    textual_mentions_gdf.plot(ax=ax, marker='s', color='purple', markersize=50, label='Textual Mentions', alpha=0.7, zorder=2)\n",
    "    \n",
    "    # Plot PIZs, color-coded by score (or number of sources)\n",
    "    # Ensure 'score' column exists and has numeric data\n",
    "    if 'score' in piz_gdf_sorted.columns and pd.api.types.is_numeric_dtype(piz_gdf_sorted['score']):\n",
    "        piz_gdf_sorted.plot(ax=ax, column='score', cmap='OrRd', alpha=0.6, \n",
    "                            legend=True, legend_kwds={'label': \"PIZ Score\"}, zorder=3)\n",
    "    else:\n",
    "        piz_gdf_sorted.plot(ax=ax, facecolor='red', alpha=0.5, label='PIZs (Unscored)', zorder=3) # Fallback if no score\n",
    "        \n",
    "    # Add labels for PIZ IDs\n",
    "    for idx, row in piz_gdf_sorted.iterrows():\n",
    "        if row.geometry.centroid.is_valid:\n",
    "            plt.text(row.geometry.centroid.x, row.geometry.centroid.y, \n",
    "                     s=f\"ID:{row.piz_id}\\nS:{row.score:.1f}\", \n",
    "                     fontsize=8, ha='center', va='center', color='black')\n",
    "        \n",
    "    plt.title(f'Potential Interest Zones (PIZs) within AOI (CRS: {piz_gdf.crs.to_string()})')\n",
    "    plt.xlabel(\"Easting\")\n",
    "    plt.ylabel(\"Northing\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(EDA_OUTPUT_DIR_PIZ / \"piz_visualization_with_scores.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No PIZs to visualize.\")\n",
    "\n",
    "# Save PIZ GeoDataFrame to a file (e.g., GeoJSON)\n",
    "if not piz_gdf_sorted.empty:\n",
    "    piz_output_path = EDA_OUTPUT_DIR_PIZ / \"piz_ranked_list.geojson\"\n",
    "    try:\n",
    "        piz_gdf_sorted.to_file(piz_output_path, driver=\"GeoJSON\")\n",
    "        print(f\"Saved ranked PIZs to: {piz_output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving PIZs to GeoJSON: {e}\")\n",
    "        # Fallback to CSV if GeoJSON fails for some reason (e.g. complex geometries not handled by driver)\n",
    "        try:\n",
    "            piz_df_for_csv = pd.DataFrame(piz_gdf_sorted.drop(columns='geometry'))\n",
    "            piz_df_for_csv['wkt_geometry'] = piz_gdf_sorted.geometry.to_wkt()\n",
    "            csv_output_path = EDA_OUTPUT_DIR_PIZ / \"piz_ranked_list.csv\"\n",
    "            piz_df_for_csv.to_csv(csv_output_path, index=False)\n",
    "            print(f\"Saved ranked PIZs (geometry as WKT) to CSV: {csv_output_path}\")\n",
    "        except Exception as e_csv:\n",
    "            print(f\"Error saving PIZs to CSV: {e_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "This notebook outlined an initial system for PIZ identification and scoring:\n",
    "1.  **PIZ Definition:** Used a buffer-and-overlap approach on placeholder EDA outputs (LiDAR, Satellite, Textual anomalies) to define PIZs where evidence from multiple sources converges. A gridding approach was also conceptually mentioned.\n",
    "2.  **Heuristic Scoring:** Implemented a scoring system based on weights and factors like the number of confirming data sources, clarity/significance of anomalies from each source, and (optionally) proximity to features like water. This produced a ranked list of PIZs.\n",
    "3.  **OpenAI Integration (Conceptual):** Showed how prompts could be formulated for top-ranked PIZs to leverage LLMs for plausibility assessment and hypothesis refinement. Actual API calls were not made in this notebook but the structure is provided.\n",
    "4.  **Visualization:** PIZs were visualized on a map, color-coded by score, along with the original anomalies and AOI boundary.\n",
    "\n",
    "**Next Steps & Refinements:**\n",
    "*   **Integrate Real EDA Outputs:** Replace placeholder anomaly data with actual outputs from the Phase 3 EDA notebooks. This will involve standardizing the format of those outputs (e.g., GeoJSON files for detected features with relevant attributes).\n",
    "*   **Refine PIZ Definition Logic:** Explore more sophisticated spatial clustering algorithms (e.g., DBSCAN on anomaly points) or the gridding approach in more detail for PIZ definition.\n",
    "*   **Tune Scoring System:** The weights and scoring parameters are initial estimates. They should be iteratively tuned based on domain expertise and feedback from verification efforts. Consider adding more nuanced parameters (e.g., size/shape of anomalies, specific feature types from text like 'earthwork' vs 'general settlement').\n",
    "*   **Automate OpenAI Interaction:** For a larger number of PIZs, the OpenAI prompt generation and API calls could be automated, with results stored alongside PIZ data.\n",
    "*   **Incorporate More Data Layers:** Integrate other relevant spatial data if available (e.g., geological maps, soil type maps, historical maps, known archaeological site distributions for context if permitted).\n",
    "*   **Verification Feedback Loop:** As top PIZs are verified (Phase 4 verification strategies), use the results to validate and improve the scoring model and PIZ identification criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
