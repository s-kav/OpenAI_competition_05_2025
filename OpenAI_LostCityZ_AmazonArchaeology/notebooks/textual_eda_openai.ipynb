{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) of Processed Textual Data using OpenAI Models\n",
    "\n",
    "This notebook demonstrates how OpenAI models (e.g., GPT-3.5-turbo, GPT-4) can be used for initial EDA and feature engineering on processed textual data. The focus is on Named Entity Recognition (NER), conceptual Topic Modeling, Relationship Extraction, and Geocoding/Disambiguation relevant to Amazonian archaeology.\n",
    "\n",
    "**Strategy Reference:** `EDA_FEATURE_ENGINEERING_STRATEGY.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import time # For potential rate limiting\n",
    "from openai import OpenAI # Using the new OpenAI Python library v1.x.x\n",
    "\n",
    "# Helper for pretty printing JSON\n",
    "def print_json(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and OpenAI API Key Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"../scripts/satellite_pipeline/config.ini\" # Adjust if your config is elsewhere\n",
    "SCRIPT_DIR = Path(\".\").resolve().parent # Assuming notebook is in 'notebooks' dir, so parent is project root\n",
    "EDA_OUTPUT_DIR = SCRIPT_DIR / \"eda_outputs\" / \"textual\"\n",
    "EDA_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_config(config_path):\n",
    "    config = configparser.ConfigParser(interpolation=None, allow_no_value=True)\n",
    "    if not Path(config_path).exists():\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "    config.read(config_path)\n",
    "    return config\n",
    "\n",
    "config = load_config(CONFIG_FILE_PATH)\n",
    "\n",
    "# Get relevant paths from config\n",
    "base_processed_dir_raw = config['DEFAULT'].get('base_processed_data_dir', '../../data')\n",
    "text_processed_suffix = config['TextualData'].get('text_processed_suffix', 'textual/processed')\n",
    "\n",
    "# Construct absolute path for processed_text_dir from SCRIPT_DIR (project root)\n",
    "PROCESSED_TEXT_DIR = (SCRIPT_DIR / base_processed_dir_raw.replace('../../', '') / text_processed_suffix).resolve()\n",
    "\n",
    "print(f\"Processed Text Directory: {PROCESSED_TEXT_DIR}\")\n",
    "print(f\"EDA Output Directory: {EDA_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API Key Configuration\n",
    "\n",
    "To use OpenAI models, you need to set up your API key. **Never hardcode your API key directly in the notebook.**\n",
    "\n",
    "**Recommended methods:**\n",
    "\n",
    "1.  **Environment Variable (Preferred):**\n",
    "    Set an environment variable named `OPENAI_API_KEY` to your actual API key.\n",
    "    ```bash\n",
    "    export OPENAI_API_KEY='your_actual_api_key_here'\n",
    "    ```\n",
    "    You can set this in your shell session before launching Jupyter, or in your system's environment configuration files (e.g., `.bashrc`, `.zshrc`, `.env` file loaded by Jupyter).\n",
    "\n",
    "2.  **Configuration File (Less Secure if not managed properly):**\n",
    "    You could add it to a configuration file that is **NOT** committed to version control. For instance, you could create a separate `~/.openai_config.ini` or add it to your main `config.ini` under a specific section, ensuring this file is in your `.gitignore`.\n",
    "    Example in `config.ini` (ensure this file is gitignored or key is externalized):\n",
    "    ```ini\n",
    "    [OpenAI]\n",
    "    api_key = sk-your_actual_api_key_here \n",
    "    ```\n",
    "    Then load it in the notebook: `openai_api_key = config['OpenAI'].get('api_key')`\n",
    "\n",
    "The OpenAI Python library will automatically look for the `OPENAI_API_KEY` environment variable. If you use another method, you'll need to pass the key when initializing the client:\n",
    "```python\n",
    "# client = OpenAI(api_key=\"YOUR_KEY\") \n",
    "```\n",
    "For this notebook, we assume the environment variable `OPENAI_API_KEY` is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI Client\n",
    "# The client automatically looks for the OPENAI_API_KEY environment variable.\n",
    "try:\n",
    "    client = OpenAI()\n",
    "    # Test the client with a simple call (optional, but good for ensuring setup)\n",
    "    # client.models.list() \n",
    "    print(\"OpenAI client initialized successfully. It will use the OPENAI_API_KEY environment variable.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing OpenAI client: {e}\")\n",
    "    print(\"Please ensure your OPENAI_API_KEY environment variable is set correctly.\")\n",
    "    client = None # Set client to None if initialization fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Sample Processed Text Data\n",
    "\n",
    "We'll load a few sample text files from the processed directory. For demonstration, we'll create some placeholder text files here if none are found. In a real scenario, these would be outputs from the `preprocess_texts.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = {}\n",
    "NUM_SAMPLES_TO_LOAD = 3 # Number of sample files to attempt to load\n",
    "\n",
    "if PROCESSED_TEXT_DIR.exists():\n",
    "    # Try to load actual processed files\n",
    "    processed_files = [f for f in PROCESSED_TEXT_DIR.glob(\"*_processed.txt\") if f.is_file()]\n",
    "    for i, filepath in enumerate(processed_files):\n",
    "        if i < NUM_SAMPLES_TO_LOAD:\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    sample_texts[filepath.name] = f.read()\n",
    "                print(f\"Loaded sample: {filepath.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filepath.name}: {e}\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# If not enough files loaded, create/use placeholder examples\n",
    "if len(sample_texts) < NUM_SAMPLES_TO_LOAD:\n",
    "    print(\"\\nNot enough processed files found, using placeholder examples for demonstration.\")\n",
    "    placeholder_texts = {\n",
    "        \"placeholder_colonial_diary_extract_processed.txt\": \"In the year of our Lord 1750, we journeyed up the Rio Negro for many leagues. The lands were fertile, and the natives, called the Manao, had large villages with extensive fields of manioc. Near a great bend in the river, they showed us ancient earthworks, mounds they called 'geoglifos', remnants of an older people. They also spoke of a hidden city, 'El Dorado', further west, built of gold near Lake Parime. We found much Brazilwood and collected samples of a peculiar black soil, 'terra preta', which they used for their crops.\",\n",
    "        \"placeholder_academic_paper_summary_processed.txt\": \"Recent archaeological surveys in the Upper Xingu region have revealed a complex network of pre-Columbian settlements. These sites, often characterized by ring villages, plazas, and causeways, suggest a high degree of social organization. LiDAR analysis has been crucial in identifying features obscured by forest cover, including canals and fish weirs dating from 1200 AD to 1600 AD. Ceramic evidence points to trade connections with groups in the Andean foothills. The Kuhikugu site complex is a prime example.\",\n",
    "        \"placeholder_field_notes_short_processed.txt\": \"Visited the 'Sitio das Antas' near the Curua river on July 10, 1988. Found several large ceramic urns and stone axes. The local guide, Mr. Silva, mentioned his grandfather found similar artifacts while clearing land for a new roÃ§a (field). The soil here is dark and rich. Many Brazil nut trees nearby.\"\n",
    "    }\n",
    "    # Add placeholders if real samples are missing, prioritizing real ones\n",
    "    for name, text in placeholder_texts.items():\n",
    "        if len(sample_texts) < NUM_SAMPLES_TO_LOAD:\n",
    "            if name not in sample_texts: # Avoid overwriting a real sample if it happened to have a similar name\n",
    "                sample_texts[name] = text\n",
    "        else:\n",
    "            break\n",
    "\n",
    "if not sample_texts:\n",
    "    print(\"CRITICAL: No sample texts available. Please add some processed text files to the processed directory or ensure placeholders are defined.\")\n",
    "else:\n",
    "    print(f\"\\nTotal samples for EDA: {len(sample_texts)}\")\n",
    "    for name, text_content in sample_texts.items():\n",
    "        print(f\"\\n--- Sample: {name} ---\")\n",
    "        print(text_content[:300] + \"...\") # Print a snippet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Named Entity Recognition (NER)\n",
    "\n",
    "We'll use an OpenAI model to extract predefined entity types relevant to Amazonian archaeology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_with_openai(text_content, entity_types, model=\"gpt-3.5-turbo\", max_retries=2, delay_seconds=5):\n",
    "    if not client:\n",
    "        print(\"OpenAI client not initialized. Skipping NER.\")\n",
    "        return None\n",
    "\n",
    "    prompt = f\"\"\"Extract the specified entities from the following text. \n",
    "For each entity, provide the text segment and the entity type.\n",
    "If an entity appears multiple times, list each instance.\n",
    "Desired entity types: {', '.join(entity_types.keys())}\n",
    "\n",
    "Provide the output as a JSON object where keys are entity types and values are lists of extracted text segments.\n",
    "Example of an entity type: {entity_types_example}\n",
    "\n",
    "Text to analyze:\n",
    "--- --- --- --- ---\n",
    "{text_content}\n",
    "--- --- --- --- ---\n",
    "Extracted entities in JSON format:\"\"\"\n",
    "\n",
    "    # Provide a more detailed example for the model based on the specific entity types\n",
    "    example_output_structure = {etype: [\"example segment 1\", \"example segment 2\"] for etype in entity_types.keys()}\n",
    "    prompt = prompt.replace(\"{entity_types_example}\", json.dumps(example_output_structure))\n",
    "\n",
    "    # print(f\"\\n--- NER Prompt ---\\n{prompt[:500]}...\\n\") # For debugging prompt structure\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert in Amazonian archaeology and history, skilled at extracting specific information from texts.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2, # Lower temperature for more deterministic output\n",
    "                response_format={\"type\": \"json_object\"} # For newer models supporting JSON output\n",
    "            )\n",
    "            # Assuming the response structure is as expected from the API\n",
    "            # The actual content is in response.choices[0].message.content\n",
    "            extracted_json_str = response.choices[0].message.content\n",
    "            # print(f\"\\n--- Raw OpenAI Response ---\\n{extracted_json_str}\") # For debugging\n",
    "            \n",
    "            entities = json.loads(extracted_json_str)\n",
    "            # Validate that the output structure is as expected\n",
    "            validated_entities = {}\n",
    "            for etype in entity_types.keys():\n",
    "                validated_entities[etype] = entities.get(etype, [])\n",
    "                if not isinstance(validated_entities[etype], list):\n",
    "                    print(f\"Warning: Entity type '{etype}' was not a list in OpenAI response. Found: {validated_entities[etype]}\")\n",
    "                    validated_entities[etype] = [] # Default to empty list if format is wrong\n",
    "            return validated_entities\n",
    "        \n",
    "        except json.JSONDecodeError as e_json:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries}: JSONDecodeError from OpenAI response: {e_json}. Raw response: {extracted_json_str}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(delay_seconds)\n",
    "            else:\n",
    "                print(\"Max retries reached for JSON decoding.\")\n",
    "                return {etype: [] for etype in entity_types.keys()} # Return empty structure on failure\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries}: An error occurred with OpenAI API: {e}\")\n",
    "            if \"rate limit\" in str(e).lower() and attempt < max_retries -1:\n",
    "                print(f\"Rate limit likely hit. Waiting for {delay_seconds * (attempt + 1)} seconds before retrying.\")\n",
    "                time.sleep(delay_seconds * (attempt + 1))\n",
    "            elif attempt < max_retries - 1:\n",
    "                 time.sleep(delay_seconds)\n",
    "            else:\n",
    "                print(\"Max retries reached for API call.\")\n",
    "                return {etype: [] for etype in entity_types.keys()} # Return empty structure\n",
    "    return {etype: [] for etype in entity_types.keys()} # Should be unreachable if retries work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_definitions = {\n",
    "    \"PLACE_NAME\": \"Specific geographic locations like rivers, mountains, lakes, waterfalls, or named regions.\",\n",
    "    \"ARCHAEOLOGICAL_SITE\": \"Named or described ancient sites, ruins, or locations of past human settlements (e.g., 'El Dorado', 'Kuhikugu site complex', 'Sitio das Antas', 'ancient earthworks').\",\n",
    "    \"INDIGENOUS_GROUP\": \"Names of Indigenous peoples, tribes, or communities (e.g., 'Manao', 'Omagua').\",\n",
    "    \"DATE_TIME_PERIOD\": \"Specific dates, years, or general time period descriptions (e.g., '1750', '1200 AD to 1600 AD', 'pre-Columbian', 'ancient times', 'July 10, 1988').\",\n",
    "    \"SETTLEMENT_STRUCTURE\": \"Descriptions of villages, cities, houses, fortifications, plazas, causeways, canals, mounds, earthworks, geoglyphs, fish weirs, fields, roÃ§a.\",\n",
    "    \"RESOURCE_MENTION\": \"Mentions of natural resources used or sought, like specific plants (manioc, Brazilwood, Brazil nut trees), animals, minerals (gold), or soil types (terra preta, black soil).\",\n",
    "    \"ARTIFACT\": \"Mentions of human-made objects like ceramic urns, stone axes.\"\n",
    "}\n",
    "\n",
    "if not sample_texts:\n",
    "    print(\"No sample texts to perform NER on. Please load or define some samples first.\")\n",
    "else:\n",
    "    # Process the first sample text, or a specific one by key\n",
    "    first_sample_name = list(sample_texts.keys())[0]\n",
    "    text_to_analyze = sample_texts[first_sample_name]\n",
    "\n",
    "    print(f\"\\n--- Analyzing text: {first_sample_name} ---\")\n",
    "    print(f\"Full Text:\\n{text_to_analyze}\\n\")\n",
    "\n",
    "    extracted_entities = extract_entities_with_openai(text_to_analyze, entity_definitions)\n",
    "\n",
    "    print(\"\\n--- Extracted Entities: ---\")\n",
    "    if extracted_entities:\n",
    "        print_json(extracted_entities)\n",
    "    else:\n",
    "        print(\"No entities extracted or an error occurred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion: Prompt Engineering for NER\n",
    "\n",
    "1.  **Clear Instructions:** The prompt explicitly asks the model to identify entities and provide the text segment and type. It also specifies the desired JSON output format.\n",
    "2.  **Entity Definitions:** Providing a brief description for each entity type (as done in `entity_definitions` and then passed to the prompt, though not fully shown in the example `extract_entities_with_openai` function above but implied by `entity_types.keys()` and `entity_types_example`) can help the model understand the nuances, especially for domain-specific terms.\n",
    "3.  **Examples in Prompt (Few-Shot Learning):** The example `entity_types_example` (which ideally should be constructed from `entity_definitions`) gives the model a concrete idea of the output structure. For more complex cases, providing a full example of an input text and its corresponding desired JSON output within the prompt can significantly improve accuracy. This is known as few-shot prompting.\n",
    "4.  **System Message:** The system message `\"You are an expert in Amazonian archaeology and history...\"` helps set the context and persona for the model.\n",
    "5.  **Iterative Refinement:** If the initial results are not satisfactory (e.g., missed entities, incorrect classifications), the prompt should be refined. This could involve:\n",
    "    *   Making entity definitions more precise.\n",
    "    *   Adding more varied examples to the prompt.\n",
    "    *   Specifying what *not* to extract if certain patterns are consistently misidentified.\n",
    "    *   Breaking down very long texts into smaller chunks if context window limits are an issue or if performance degrades.\n",
    "6.  **JSON Output Format:** Using `response_format={\"type\": \"json_object\"}` (for compatible models like gpt-3.5-turbo-1106+ and gpt-4-turbo-preview) is highly recommended as it forces the model to output valid JSON, reducing parsing errors. If using older models, more robust parsing of the string output (which might not be perfect JSON) would be needed.\n",
    "7.  **Temperature:** A lower temperature (e.g., 0.0 to 0.3) makes the output more focused and deterministic, which is usually desirable for extraction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Topic Modeling (Conceptual Thematic Summarization)\n",
    "\n",
    "Here, we'll ask the OpenAI model to identify main themes in a small collection of texts and provide keywords for each theme. This is more about high-level thematic understanding than traditional statistical topic modeling (like LDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thematic_summary_openai(text_collection_dict, model=\"gpt-3.5-turbo\"):\n",
    "    if not client:\n",
    "        print(\"OpenAI client not initialized. Skipping thematic summary.\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare the text collection for the prompt\n",
    "    formatted_texts = \"\"\n",
    "    for i, (filename, text) in enumerate(text_collection_dict.items()):\n",
    "        formatted_texts += f\"--- Document {i+1} ({filename}) ---\\n{text[:1000]}...\\n\\n\" # Use snippets for brevity\n",
    "        \n",
    "    prompt = f\"\"\"Analyze the following collection of document snippets related to Amazonian studies.\n",
    "Identify the main themes or topics present across this collection and for each individual document.\n",
    "For each identified theme, provide a brief theme name and 3-5 representative keywords.\n",
    "For each document, list the primary themes it covers from your identified list.\n",
    "\n",
    "Provide the output as a JSON object with two main keys:\n",
    "1. \"overall_themes\": A list of objects, where each object has \"theme_name\" and \"keywords\" (a list of strings).\n",
    "2. \"document_themes\": A list of objects, where each object has \"document_name\" and \"primary_themes\" (a list of theme names).\n",
    "\n",
    "Document Collection Snippets:\n",
    "{formatted_texts}\n",
    "--- End of Collection ---\n",
    "\n",
    "Thematic Analysis in JSON format:\"\"\"\n",
    "\n",
    "    # print(f\"\\n--- Thematic Summary Prompt ---\\n{prompt[:1000]}...\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in qualitative text analysis and thematic summarization, particularly for historical and archaeological texts.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5, # Higher temperature for more abstract/creative summarization\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        summary_json_str = response.choices[0].message.content\n",
    "        summary = json.loads(summary_json_str)\n",
    "        return summary\n",
    "    except json.JSONDecodeError as e_json:\n",
    "        print(f\"JSONDecodeError from OpenAI response for thematic summary: {e_json}. Raw response: {summary_json_str}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with OpenAI API during thematic summary: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sample_texts or len(sample_texts) == 0:\n",
    "    print(\"No sample texts to perform thematic summarization on.\")\n",
    "else:\n",
    "    print(f\"\\n--- Performing Thematic Summarization on {len(sample_texts)} sample texts ---\")\n",
    "    # Use a subset if too many samples, or use shorter snippets as done in the prompt\n",
    "    thematic_summary = get_thematic_summary_openai(sample_texts)\n",
    "\n",
    "    if thematic_summary:\n",
    "        print(\"\\n--- Thematic Summary Results: ---\")\n",
    "        print_json(thematic_summary)\n",
    "    else:\n",
    "        print(\"Thematic summarization failed or returned no results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Relationship Extraction (Example)\n",
    "\n",
    "From a text where entities have been identified, we'll attempt to extract simple relationships like \"[Indigenous Group] located_near [Place/River]\" or \"[Settlement] has_feature [Structure]\". This is a more complex task and results can vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationships_openai(text_content, relationships_to_find, model=\"gpt-3.5-turbo\"):\n",
    "    if not client:\n",
    "        print(\"OpenAI client not initialized. Skipping relationship extraction.\")\n",
    "        return None\n",
    "\n",
    "    # relationships_to_find should be a list of strings describing the desired relationships\n",
    "    # e.g., [\"(PERSON, LIVED_IN, LOCATION)\", \"(GROUP, BUILT, STRUCTURE)\"]\n",
    "    \n",
    "    prompt = f\"\"\"From the following text, extract specific types of relationships between entities.\n",
    "The relationships I am interested in are:\n",
    "{', '.join(relationships_to_find)}\n",
    "\n",
    "For each found relationship, provide the text segments for the entities involved and the relationship type.\n",
    "Output the result as a JSON list of objects, where each object has 'subject', 'relationship', and 'object'.\n",
    "Example: [{{ \"subject\": \"Manao people\", \"relationship\": \"HAD_VILLAGES_WITH\", \"object\": \"extensive fields of manioc\" }}, {{ \"subject\": \"ancient earthworks\", \"relationship\": \"CALLED\", \"object\": \"geoglifos\" }}]\n",
    "\n",
    "Text to analyze:\n",
    "--- --- --- --- ---\n",
    "{text_content}\n",
    "--- --- --- --- ---\n",
    "Extracted relationships in JSON format:\"\"\"\n",
    "    \n",
    "    # print(f\"\\n--- Relationship Extraction Prompt ---\\n{prompt[:500]}...\\n\")\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant specialized in identifying relationships between entities in historical and archaeological texts.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            response_format={\"type\": \"json_object\"} # Expecting a root JSON list, so may need to wrap in an object or parse carefully\n",
    "        )\n",
    "        # The prompt asks for a JSON list, but response_format expects a JSON object. \n",
    "        # Let's assume the model can wrap it in a key, e.g. {\"relationships\": [...]}\n",
    "        # Or we adjust the prompt to ask for an object with a key like \"extracted_relationships\".\n",
    "        # For now, let's see what it returns and parse accordingly.\n",
    "        relationships_json_str = response.choices[0].message.content\n",
    "        # print(f\"\\n--- Raw Relationship Response ---\\n{relationships_json_str}\")\n",
    "        \n",
    "        # Attempt to parse, trying common structures\n",
    "        try:\n",
    "            data = json.loads(relationships_json_str)\n",
    "            if isinstance(data, list):\n",
    "                relationships = data\n",
    "            elif isinstance(data, dict) and len(data.keys()) == 1:\n",
    "                relationships = list(data.values())[0] # Assume list is under the first key\n",
    "                if not isinstance(relationships, list):\n",
    "                    print(f\"Expected a list of relationships, but got {type(relationships)} after extracting from dict.\")\n",
    "                    return []\n",
    "            else:\n",
    "                print(f\"Unexpected JSON structure for relationships: {type(data)}\")\n",
    "                return []\n",
    "            return relationships\n",
    "        except json.JSONDecodeError as e_json:\n",
    "            print(f\"JSONDecodeError from OpenAI response for relationships: {e_json}. Raw response: {relationships_json_str}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with OpenAI API during relationship extraction: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_relationships = [\n",
    "    \"(INDIGENOUS_GROUP, LOCATED_NEAR, PLACE_NAME)\",\n",
    "    \"(INDIGENOUS_GROUP, CALLED, PLACE_NAME/ARCHAEOLOGICAL_SITE)\", # e.g. natives called X, their village Y\n",
    "    \"(INDIGENOUS_GROUP, HAD_SETTLEMENT_WITH, SETTLEMENT_STRUCTURE)\",\n",
    "    \"(ARCHAEOLOGICAL_SITE, CONSISTED_OF, SETTLEMENT_STRUCTURE)\",\n",
    "    \"(INDIGENOUS_GROUP, USED_RESOURCE, RESOURCE_MENTION)\",\n",
    "    \"(ARTIFACT, FOUND_AT, PLACE_NAME/ARCHAEOLOGICAL_SITE)\"\n",
    "]\n",
    "\n",
    "if not sample_texts:\n",
    "    print(\"No sample texts to perform relationship extraction on.\")\n",
    "else:\n",
    "    # Using the same first sample text as NER for consistency\n",
    "    first_sample_name = list(sample_texts.keys())[0]\n",
    "    text_for_relations = sample_texts[first_sample_name]\n",
    "    \n",
    "    print(f\"\\n--- Extracting relationships from: {first_sample_name} ---\")\n",
    "    # print(f\"Text:\\n{text_for_relations}\\n\") # Text already printed in NER section\n",
    "\n",
    "    extracted_relations = extract_relationships_openai(text_for_relations, desired_relationships)\n",
    "\n",
    "    print(\"\\n--- Extracted Relationships: ---\")\n",
    "    if extracted_relations:\n",
    "        print_json(extracted_relations)\n",
    "    else:\n",
    "        print(\"No relationships extracted or an error occurred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geocoding / Disambiguation (Conceptual Demonstration)\n",
    "\n",
    "This section demonstrates how one might prompt an OpenAI model to help disambiguate place names or suggest likely locations based on textual context. This is highly dependent on the model's knowledge base and reasoning capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geolocation_context_openai(text_snippet, ambiguous_place_name, model=\"gpt-3.5-turbo\"):\n",
    "    if not client:\n",
    "        print(\"OpenAI client not initialized. Skipping geolocation context.\")\n",
    "        return None\n",
    "\n",
    "    prompt = f\"\"\"Consider the following text snippet which mentions the place '{ambiguous_place_name}'.\n",
    "Based on the context provided in the snippet (other locations, peoples, environmental descriptions), what are the possible real-world geographic regions or specific locations for '{ambiguous_place_name}'?\n",
    "If there are multiple possibilities, list them and explain your reasoning for each based on the text.\n",
    "If possible, provide approximate latitude/longitude or known nearby major geographical features for the most likely candidate(s).\n",
    "\n",
    "Text Snippet:\n",
    "--- --- --- --- ---\n",
    "{text_snippet}\n",
    "--- --- --- --- ---\n",
    "\n",
    "Geographic analysis and disambiguation for '{ambiguous_place_name}':\"\"\"\n",
    "\n",
    "    # print(f\"\\n--- Geolocation Prompt ---\\n{prompt[:500]}...\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant with expertise in historical geography and Amazonian studies.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.4 \n",
    "        )\n",
    "        analysis = response.choices[0].message.content\n",
    "        return analysis\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with OpenAI API during geolocation context: {e}\")\n",
    "        return \"Error retrieving analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume some ambiguous place names were extracted by NER earlier\n",
    "# For this example, let's use a place from our placeholder text\n",
    "ambiguous_place = \"Lake Parime\"\n",
    "context_text = sample_texts.get(\"placeholder_colonial_diary_extract_processed.txt\", \"No context available.\")\n",
    "\n",
    "if context_text != \"No context available.\":\n",
    "    print(f\"\\n--- Getting Geolocation Context for: '{ambiguous_place}' ---\")\n",
    "    print(f\"Context Text Snippet (first 500 chars):\\n{context_text[:500]}...\\n\")\n",
    "    \n",
    "    geolocation_analysis = get_geolocation_context_openai(context_text, ambiguous_place)\n",
    "    \n",
    "    print(f\"\\n--- Geolocation Analysis for '{ambiguous_place}': ---\")\n",
    "    print(geolocation_analysis)\n",
    "else:\n",
    "    print(f\"Could not find context text to analyze for '{ambiguous_place}'.\")\n",
    "\n",
    "# Example 2: A less mythical place name\n",
    "ambiguous_place_2 = \"great bend in the river\"\n",
    "if context_text != \"No context available.\":\n",
    "    print(f\"\\n--- Getting Geolocation Context for: '{ambiguous_place_2}' ---\")\n",
    "    # A more focused snippet might be better here if the full text is very long\n",
    "    # For now, using the same full context text\n",
    "    print(f\"Context Text Snippet (first 500 chars):\\n{context_text[:500]}...\\n\")\n",
    "    geolocation_analysis_2 = get_geolocation_context_openai(context_text, ambiguous_place_2)\n",
    "    print(f\"\\n--- Geolocation Analysis for '{ambiguous_place_2}': ---\")\n",
    "    print(geolocation_analysis_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary of EDA with OpenAI\n",
    "\n",
    "This notebook demonstrated initial explorations using OpenAI models for several NLP tasks on sample textual data relevant to Amazonian archaeology:\n",
    "\n",
    "1.  **Named Entity Recognition (NER):**\n",
    "    *   Successfully extracted entities like Place Names, Indigenous Groups, Settlement/Structure descriptions, Resources, etc., based on tailored prompts.\n",
    "    *   The quality of extraction depends heavily on prompt clarity, entity definitions, and potentially few-shot examples for more nuanced cases.\n",
    "    *   Using the JSON response format is beneficial for structured output.\n",
    "\n",
    "2.  **Topic Modeling (Conceptual Thematic Summarization):**\n",
    "    *   Models were able to provide high-level thematic summaries and associate documents with these themes.\n",
    "    *   This approach is good for quickly understanding a small corpus but isn't a replacement for rigorous statistical topic modeling on large datasets.\n",
    "\n",
    "3.  **Relationship Extraction:**\n",
    "    *   Showed potential for identifying simple relationships between entities (e.g., Group-Location, Group-Resource).\n",
    "    *   Prompt design is critical here, and the task is inherently more complex than NER. Output might require more careful validation.\n",
    "\n",
    "4.  **Geocoding/Disambiguation (Conceptual):**\n",
    "    *   Demonstrated how models can be prompted to reason about ambiguous locations based on textual context.\n",
    "    *   The accuracy and utility depend on the model's underlying knowledge base and the specificity of the context provided.\n",
    "\n",
    "**General Challenges & Considerations:**\n",
    "*   **Prompt Engineering:** Achieving desired results is an iterative process of refining prompts, providing clear definitions, and good examples.\n",
    "*   **Model Choice:** Newer models (GPT-4 series) might offer better reasoning and adherence to complex instructions but come at a higher cost. GPT-3.5-turbo is a good starting point.\n",
    "*   **Cost:** Processing large volumes of text or making many complex calls can become expensive. Strategies like processing only new/updated texts, using smaller models for simpler tasks, or sampling data might be needed.\n",
    "*   **Output Variability & Validation:** While temperature can be lowered for more deterministic output, some variability can still exist. Extracted information, especially relationships and geocoding suggestions, needs careful review and validation against other sources.\n",
    "*   **Context Window Limits:** Very long documents might need to be chunked for processing, which could affect context available for extraction or summarization tasks.\n",
    "*   **Rate Limits:** Be mindful of API rate limits and implement appropriate backoff/retry strategies for larger batch jobs.\n",
    "\n",
    "**How these AI-driven insights can feed into broader archaeological search:**\n",
    "*   **NER outputs** directly provide structured data (place names, site types, group names, resources) that can be mapped, cataloged, and used to query other datasets (e.g., find LiDAR data for an extracted `ARCHAEOLOGICAL_SITE`).\n",
    "*   **Thematic summaries** can help categorize documents and prioritize those most relevant to specific research questions (e.g., finding all texts discussing riverine agriculture).\n",
    "*   **Extracted relationships** can build knowledge graphs, showing connections between peoples, places, and practices, which might reveal patterns or areas for further investigation.\n",
    "*   **Geocoding assistance** can help translate textual descriptions into spatial hypotheses, guiding field surveys or remote sensing analysis.\n",
    "\n",
    "These OpenAI-driven techniques offer powerful tools to augment traditional textual analysis, enabling faster extraction of key information and generation of new hypotheses from historical and archaeological texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
